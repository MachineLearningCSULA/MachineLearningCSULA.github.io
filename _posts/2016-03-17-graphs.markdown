---
layout: post
title:  "Graphs"
categories: jekyll update
---

<a class="btn btn-primary" role="button" data-toggle="collapse" href="#collapseExample2" aria-expanded="false" aria-controls="collapseExample">
  Confusion Matrix
</a>
<button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#collapseExample" aria-expanded="false" aria-controls="collapseExample">
  Bias and Variance
</button>
<button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#collapseExample3" aria-expanded="false" aria-controls="collapseExample">
  Receiving Operating Characteristic
</button>
<div class="collapse" id="collapseExample">
  <div class="well">
  <h2>Naive Bayes</h2>
  <img src="/assets/nb_rms_vs_train.png" />
  <!-- <caption>Learning Curve</caption> -->
  <h2>Random Forest</h2>
  <img src="/assets/rf_rms_vs_train.png" />
  <p>Training Curve: Artificially Restrict Training size, As training set grows, error grows.</p>
  <p>Cross Validation: Stand in for test data, check to see if trained data is generalizable to test set.  So, with increased training set size, cross validation error should decrease.</p>
  <p>A large gap between the cross validation error curve and training error curve suggests high variance (Overfitting), cross validation error will remain high.  If the cross validation error curve and training error curve are very close to each other there is high bias (Underfitting).  Our study suggests that our model has some overfitting for the naive bayes classifier.</p>
  <p>The learning curve suggests our model needs additional training data because of the high variance.</p>
  </div>
</div>
<div class="collapse" id="collapseExample2">
  <div class="well">
      <h2>Confusion Matrix: Naive Bayes, Logistic Regression, Random Forest</h2>
      <img src="/assets/nb_confus_matrix.png" />
      <!-- <h2>Confusion Matrix: Logistic Regression</h2> -->
      <img src="/assets/lg_confus_matrix.png" />
      <!-- <h2>Confusion Matrix: SVM</h2> -->
      <img src="/assets/svm_confus_matrix.png" />
      <!-- <h2>Confusion Matrix: Random Forest </h2> -->
      <img src="/assets/rf_confus_matrix.png" />
      <p>Confusion Matrix compares actual class with predicted class.  In our study true negative is upper left, true positive is lower right.  False negative is lower left and false positive is upper right.  This shows that our classifiers often predict movies to be unsuccessful.</p>
  </div>
</div>
<div class="collapse" id="collapseExample3">
  <div class="well">
      <h2>Receiving Operating Characteristic</h2>
      <img src="/assets/roc_samplev2.png" />
      <p>ROC Curve: common way to visual performance of binary classifier, in our study the ROC curve shows the performance of the various classifiers we used for predicting successful or not successful movies.</p>
      <p>True Positive: When actual classification is positive how often does classifier predict positive?</p>
      <p>False Positive: When actual classification is negative how often does classify incorrectly predict positive.</p>
      <p>Movement along the ROC curve will give the True Positive vs False Positive rates of a given classification threshold for the classifier.</p>
      <p>Closer to diagonal line means closer to random guessing</p>
      <p>AUC: Area Under the Curve.  Higher AUC is better, 1 is a perfect classifier, 0.5 is random guessing.  For this study SVM was same as random guessing.</p>
  </div>
</div>
<!-- <h2>Naive Bayes</h2>
<img src="/assets/nb_rms_vs_train.png" />
<caption>Blah Blah</caption>
<h2>Random Forest</h2>
<img src="/assets/rf_rms_vs_train.png" />
<hr>
<h2>Confusion Matrix: Naive Bayes</h2>
<img src="/assets/nb_confus_matrix.png" />
<h2>Confusion Matrix: Logistic Regression</h2>
<img src="/assets/lg_confus_matrix.png" />
<h2>Confusion Matrix: SVM</h2>
<img src="/assets/svm_confus_matrix.png" />
<h2>Confusion Matrix: Random Forest </h2>
<img src="/assets/rf_confus_matrix.png" />
<hr>
<h2>Receiving Operator Char </h2>
<img src="/assets/roc_sample.png" />
<h2>Receiving Operator Char </h2>
<img src="/assets/roc_samplev2.png" />
<h2>Receiving Operator Char </h2>
<img src="/assets/roc_lg_sample.png" /> -->

<h1>Strong Conclusions</h1>
<ul>
    <li>We can predict with about 70% accuracy the success of new film</li>
    <li>We need access to larger date sensitive data from Twitter to make this prediction more accurate</li>
    <li>ROC Curve shows that Naive Bayes and Logisitic Regression were the best classifiers while SVM was as bad as random guessing.</li>
    <li>The confusion matrix shows that the model almost always predicts movies to be unsuccessful and has a high false negative rate.</li>
    <li>The learning curve suggests our model requires additional training data because of the suggested high variance.</li>
</ul>
   